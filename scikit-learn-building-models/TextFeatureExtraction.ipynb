{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Extracting Features from Text\n",
    "\n",
    "This notebook will cover how we can extract features from a corpus of text documents. This will go over how what a bag of words is and how to use it, we will also cover TF-IDF Transformation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a corpus of 4 documents with some repeated values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = ['This is the first document.',\n",
    "          'This is the second document.', \n",
    "          'Third document. Document number three', \n",
    "          'Number four. To repeat, number four']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use CountVectorizer to convert a collection of text documents to a \"bag of words\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4x12 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 18 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "bag_of_words = vectorizer.fit_transform(corpus)\n",
    "\n",
    "bag_of_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View what the \"bag\" looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 9)\t1\n",
      "  (0, 3)\t1\n",
      "  (0, 7)\t1\n",
      "  (0, 1)\t1\n",
      "  (0, 0)\t1\n",
      "  (1, 9)\t1\n",
      "  (1, 3)\t1\n",
      "  (1, 7)\t1\n",
      "  (1, 0)\t1\n",
      "  (1, 6)\t1\n",
      "  (2, 0)\t2\n",
      "  (2, 8)\t1\n",
      "  (2, 4)\t1\n",
      "  (2, 10)\t1\n",
      "  (3, 4)\t2\n",
      "  (3, 2)\t2\n",
      "  (3, 11)\t1\n",
      "  (3, 5)\t1\n"
     ]
    }
   ],
   "source": [
    "print(bag_of_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the value to which a word is mapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.vocabulary_.get('document')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'this': 9,\n",
       " 'is': 3,\n",
       " 'the': 7,\n",
       " 'first': 1,\n",
       " 'document': 0,\n",
       " 'second': 6,\n",
       " 'third': 8,\n",
       " 'number': 4,\n",
       " 'three': 10,\n",
       " 'four': 2,\n",
       " 'to': 11,\n",
       " 'repeat': 5}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>first</th>\n",
       "      <th>four</th>\n",
       "      <th>is</th>\n",
       "      <th>number</th>\n",
       "      <th>repeat</th>\n",
       "      <th>second</th>\n",
       "      <th>the</th>\n",
       "      <th>third</th>\n",
       "      <th>this</th>\n",
       "      <th>three</th>\n",
       "      <th>to</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   document  first  four  is  number  repeat  second  the  third  this  three  \\\n",
       "0         1      1     0   1       0       0       0    1      0     1      0   \n",
       "1         1      0     0   1       0       0       1    1      0     1      0   \n",
       "2         2      0     0   0       1       0       0    0      1     0      1   \n",
       "3         0      0     2   0       2       1       0    0      0     0      0   \n",
       "\n",
       "   to  \n",
       "0   0  \n",
       "1   0  \n",
       "2   0  \n",
       "3   1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(bag_of_words.toarray(), columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extend bag of words with TF-IDF weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t0.3528554929793508\n",
      "  (0, 1)\t0.5528163151092931\n",
      "  (0, 7)\t0.43584673254990375\n",
      "  (0, 3)\t0.43584673254990375\n",
      "  (0, 9)\t0.43584673254990375\n",
      "  (1, 6)\t0.5528163151092931\n",
      "  (1, 0)\t0.3528554929793508\n",
      "  (1, 7)\t0.43584673254990375\n",
      "  (1, 3)\t0.43584673254990375\n",
      "  (1, 9)\t0.43584673254990375\n",
      "  (2, 10)\t0.4850008395708102\n",
      "  (2, 4)\t0.3823802326982809\n",
      "  (2, 8)\t0.4850008395708102\n",
      "  (2, 0)\t0.6191395067937654\n",
      "  (3, 5)\t0.3432724906138499\n",
      "  (3, 11)\t0.3432724906138499\n",
      "  (3, 2)\t0.6865449812276998\n",
      "  (3, 4)\t0.5412799489419371\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "bag_of_words = vectorizer.fit_transform(corpus)\n",
    "\n",
    "print(bag_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.vocabulary_.get('document')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>first</th>\n",
       "      <th>four</th>\n",
       "      <th>is</th>\n",
       "      <th>number</th>\n",
       "      <th>repeat</th>\n",
       "      <th>second</th>\n",
       "      <th>the</th>\n",
       "      <th>third</th>\n",
       "      <th>this</th>\n",
       "      <th>three</th>\n",
       "      <th>to</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.352855</td>\n",
       "      <td>0.552816</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.435847</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.435847</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.435847</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.352855</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.435847</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.552816</td>\n",
       "      <td>0.435847</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.435847</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.619140</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.38238</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.485001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.485001</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.686545</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.54128</td>\n",
       "      <td>0.343272</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.343272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   document     first      four        is   number    repeat    second  \\\n",
       "0  0.352855  0.552816  0.000000  0.435847  0.00000  0.000000  0.000000   \n",
       "1  0.352855  0.000000  0.000000  0.435847  0.00000  0.000000  0.552816   \n",
       "2  0.619140  0.000000  0.000000  0.000000  0.38238  0.000000  0.000000   \n",
       "3  0.000000  0.000000  0.686545  0.000000  0.54128  0.343272  0.000000   \n",
       "\n",
       "        the     third      this     three        to  \n",
       "0  0.435847  0.000000  0.435847  0.000000  0.000000  \n",
       "1  0.435847  0.000000  0.435847  0.000000  0.000000  \n",
       "2  0.000000  0.485001  0.000000  0.485001  0.000000  \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.343272  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(bag_of_words.toarray(), columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View all the words and their corresponding values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'this': 9,\n",
       " 'is': 3,\n",
       " 'the': 7,\n",
       " 'first': 1,\n",
       " 'document': 0,\n",
       " 'second': 6,\n",
       " 'third': 8,\n",
       " 'number': 4,\n",
       " 'three': 10,\n",
       " 'four': 2,\n",
       " 'to': 11,\n",
       " 'repeat': 5}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Hashing Vectorizer\n",
    "* One issue with CountVectorizer and TF-IDF Vectorizer is that the number of features can get very large if the vocabulary is very large\n",
    "* The whole vocabulary will be stored in memory, and this may end up taking a lot of space\n",
    "* With Hashing Vectorizer, one can limit the number of features, let's say to a number <b>n</b>\n",
    "* Each word will be hashed to one of the n values\n",
    "* There will collisions where different words will be hashed to the same value\n",
    "* In many instances, peformance does not really suffer in spite of the collisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t-0.8944271909999159\n",
      "  (0, 5)\t0.4472135954999579\n",
      "  (0, 6)\t0.0\n",
      "  (1, 0)\t-0.5773502691896258\n",
      "  (1, 3)\t0.5773502691896258\n",
      "  (1, 5)\t0.5773502691896258\n",
      "  (1, 6)\t0.0\n",
      "  (2, 0)\t-0.7559289460184544\n",
      "  (2, 3)\t0.3779644730092272\n",
      "  (2, 5)\t0.3779644730092272\n",
      "  (2, 7)\t0.3779644730092272\n",
      "  (3, 0)\t0.31622776601683794\n",
      "  (3, 3)\t0.31622776601683794\n",
      "  (3, 5)\t0.6324555320336759\n",
      "  (3, 7)\t0.6324555320336759\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "vectorizer = HashingVectorizer(n_features=8)\n",
    "feature_vector = vectorizer.fit_transform(corpus)\n",
    "print(feature_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### There is no way to compute the inverse transform to get the words from the hashed value"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
